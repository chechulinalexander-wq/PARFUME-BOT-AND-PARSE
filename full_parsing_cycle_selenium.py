import sqlite3
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import sys
import io
import time
import unicodedata
import re
from rapidfuzz import fuzz
from datetime import datetime
import cloudscraper
import warnings

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

# –§–∏–∫—Å –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows –∫–æ–Ω—Å–æ–ª–∏
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò
# ============================================================================

MAX_PRODUCTS = 1000
CATALOG_URL = 'https://randewoo.ru/category/parfyumeriya'

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò SMARTPROXY
# ============================================================================

SMARTPROXY_HOST = "proxy.smartproxy.net"
SMARTPROXY_PORT = 3120
SMARTPROXY_USER = "smart-qad2gx6xmehj"
SMARTPROXY_PASS = "twYMsn3pEJ4DqZqk"

# –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø—Ä–æ–∫—Å–∏
PROXY_URL = f"http://{SMARTPROXY_USER}:{SMARTPROXY_PASS}@{SMARTPROXY_HOST}:{SMARTPROXY_PORT}"

# ============================================================================
# –®–ê–ì 1: –û–ß–ò–°–¢–ö–ê –ë–î
# ============================================================================

def clear_database():
    """–û—á–∏—â–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã randewoo_products –∏ perfume_news"""
    print("\n" + "="*80, flush=True)
    print("–®–ê–ì 1: –û–ß–ò–°–¢–ö–ê –ë–î", flush=True)
    print("="*80 + "\n", flush=True)
    
    conn = sqlite3.connect('fragrantica_news.db')
    cursor = conn.cursor()
    
    cursor.execute('SELECT COUNT(*) FROM perfume_news')
    news_count = cursor.fetchone()[0]
    cursor.execute('DELETE FROM perfume_news')
    print(f"‚úì –£–¥–∞–ª–µ–Ω–æ {news_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ perfume_news")
    
    cursor.execute('SELECT COUNT(*) FROM randewoo_products')
    products_count = cursor.fetchone()[0]
    cursor.execute('DELETE FROM randewoo_products')
    print(f"‚úì –£–¥–∞–ª–µ–Ω–æ {products_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ randewoo_products")
    
    conn.commit()
    conn.close()
    
    print("\n‚úì –¢–∞–±–ª–∏—Ü—ã –æ—á–∏—â–µ–Ω—ã")

# ============================================================================
# –®–ê–ì 2: –ü–ê–†–°–ò–ù–ì RANDEWOO –° SELENIUM
# ============================================================================

def parse_randewoo_with_selenium(max_products=1000):
    """–ü–∞—Ä—Å–∏—Ç –∫–∞—Ç–∞–ª–æ–≥ Randewoo –∏—Å–ø–æ–ª—å–∑—É—è Selenium"""
    print("\n" + "="*80, flush=True)
    print(f"–®–ê–ì 2: –ü–ê–†–°–ò–ù–ì RANDEWOO (–ª–∏–º–∏—Ç: {max_products} —Ç–æ–≤–∞—Ä–æ–≤)", flush=True)
    print("="*80 + "\n", flush=True)
    
    conn = sqlite3.connect('fragrantica_news.db', timeout=30)
    cursor = conn.cursor()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î
    cursor.execute('SELECT COUNT(*) FROM randewoo_products')
    existing_count = cursor.fetchone()[0]
    print(f"üìä –¢–æ–≤–∞—Ä–æ–≤ –≤ –ë–î: {existing_count}", flush=True)
    
    if existing_count >= max_products:
        print(f"‚úì –õ–∏–º–∏—Ç —É–∂–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç ({existing_count}/{max_products})")
        conn.close()
        return existing_count
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Chrome
    options = uc.ChromeOptions()
    options.headless = True  # –ë–µ–∑ GUI
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    
    print("‚è≥ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Chrome (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10-20 —Å–µ–∫)...", flush=True)
    print("   (–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ...)", flush=True)
    
    driver = uc.Chrome(options=options, version_main=None)
    
    print("‚úì Chrome –∑–∞–ø—É—â–µ–Ω!", flush=True)
    
    all_products = []
    page = 1
    
    try:
        while len(all_products) < max_products:
            if page == 1:
                page_url = CATALOG_URL
            else:
                page_url = f"{CATALOG_URL}?page={page}"
            
            print(f"\n–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {page_url}", flush=True)
            
            try:
                print("  üåê –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...", end=" ", flush=True)
                driver.get(page_url)
                print("‚úì", flush=True)
                
                # –ù–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –≤ URL –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º
                if page == 1:
                    print("  üîΩ –ü—Ä–∏–º–µ–Ω—è—é —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –ø–æ –æ—Ç–∑—ã–≤–∞–º...", end=" ", flush=True)
                    
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ URL —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π
                    sorted_url = f"{CATALOG_URL}?sorting=comments_count"
                    driver.get(sorted_url)
                    
                    print("‚úì", flush=True)
                    print("  ‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (10 —Å–µ–∫)...", end=" ", flush=True)
                    time.sleep(10)
                    print("‚úì", flush=True)
                else:
                    print("  ‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ JS (8 —Å–µ–∫)...", end=" ", flush=True)
                    time.sleep(8)
                    print("‚úì", flush=True)
                
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                
                products = soup.find_all('li', class_='products__item')
                
                if not products:
                    print(f"  ‚ö† –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                    break
                
                print(f"  –ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
                
                for product in products:
                    if len(all_products) >= max_products:
                        break
                    
                    try:
                        brand_div = product.find('div', class_='b-catalogItem__brand')
                        name_div = product.find('div', class_='b-catalogItem__name')
                        link = product.find('a', class_='b-catalogItem__descriptionLink')
                        
                        if brand_div and name_div and link:
                            brand = brand_div.get_text(strip=True)
                            name = name_div.get_text(strip=True)
                            product_url = urljoin('https://randewoo.ru', link['href'])
                            
                            cursor.execute('''
                                INSERT OR IGNORE INTO randewoo_products (brand, name, product_url)
                                VALUES (?, ?, ?)
                            ''', (brand, name, product_url))
                            
                            all_products.append({'brand': brand, 'name': name, 'url': product_url})
                            
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä
                            print(f"  [{len(all_products)}/{max_products}] {brand} - {name}")
                            
                    except Exception as e:
                        print(f"  ‚ö† –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞: {e}")
                
                conn.commit()
                print(f"  –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {len(all_products)}/{max_products}")
                
                if len(all_products) >= max_products:
                    print(f"\n‚úì –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤ {max_products} —Ç–æ–≤–∞—Ä–æ–≤")
                    break
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
                pagination = soup.find('ol', class_='pager')
                if pagination:
                    next_link = pagination.find('a', class_='pager__link--forward')
                    if not next_link:
                        print(f"\n‚úì –ë–æ–ª—å—à–µ –Ω–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü")
                        break
                else:
                    print(f"\n‚ö† –ü–∞–≥–∏–Ω–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    break
                
                page += 1
                
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
                break
    
    finally:
        driver.quit()
        conn.close()
    
    print(f"\n‚úì –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")
    return len(all_products)

# ============================================================================
# –®–ê–ì 3: –ü–û–ò–°–ö –ù–ê FRAGRANTICA
# ============================================================================

def normalize_text(text):
    text = text.lower()
    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')
    text = re.sub(r'[^a-z0-9]+', ' ', text)
    return text.strip()

def search_fragrantica(scraper, brand, name, brand_cache):
    """–ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏–∑ add_fragrantica_url_final.py"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à –±—Ä–µ–Ω–¥–∞
    brand_key = brand.lower().strip()
    if brand_key in brand_cache:
        perfume_links = brand_cache[brand_key]
        
        name_normalized = normalize_text(name)
        name_lower = name.lower().strip()
        
        best_match = None
        best_match_score = 0
        
        for plink in perfume_links:
            purl = plink['url']
            ptext = plink['text']
            
            ptext_normalized = normalize_text(ptext)
            ptext_lower = ptext.lower().strip()
            
            if name_normalized == ptext_normalized:
                return purl
            
            fuzzy_score = fuzz.token_sort_ratio(name_lower, ptext_lower)
            partial_score = fuzz.partial_ratio(name_lower, ptext_lower)
            token_set_score = fuzz.token_set_ratio(name_lower, ptext_lower)
            
            max_fuzzy_score = max(fuzzy_score, partial_score, token_set_score)
            
            if max_fuzzy_score > best_match_score and max_fuzzy_score >= 70:
                best_match = purl
                best_match_score = max_fuzzy_score
            
            if len(name_normalized) > 5:
                name_words = set(name_lower.split())
                ptext_words = set(ptext_lower.split())
                common_words = name_words & ptext_words
                
                if len(name_words) > 0:
                    word_match_ratio = len(common_words) / len(name_words) * 100
                    
                    if word_match_ratio > best_match_score and word_match_ratio >= 70:
                        best_match = purl
                        best_match_score = word_match_ratio
        
        if best_match and best_match_score >= 70:
            return best_match
        
        return None
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±—Ä–µ–Ω–¥–∞
    brand_variants = [
        brand.replace(' ', '-'),
        brand,
    ]
    
    brand_page_url = None
    perfume_links = []
    
    for brand_variant in brand_variants:
        test_url = f"https://www.fragrantica.ru/designers/{brand_variant}.html"
        
        try:
            response = scraper.get(test_url, timeout=10)
            
            if response.status_code == 200:
                brand_page_url = test_url
                break
        except:
            continue
        
        time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ URL –±—Ä–µ–Ω–¥–∞
    
    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –±—Ä–µ–Ω–¥–∞
    if brand_page_url:
        try:
            time.sleep(2)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±—Ä–µ–Ω–¥–∞
            response = scraper.get(brand_page_url, timeout=30)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            perfume_links_raw = soup.find_all('a', href=lambda x: x and '/perfume/' in x)
            
            name_normalized = normalize_text(name)
            name_lower = name.lower().strip()
            result_url = None
            best_match_score = 0
            
            for plink in perfume_links_raw:
                purl = urljoin('https://www.fragrantica.ru', plink.get('href'))
                ptext = plink.get_text(strip=True)
                perfume_links.append({'url': purl, 'text': ptext})
                
                ptext_normalized = normalize_text(ptext)
                ptext_lower = ptext.lower().strip()
                
                if name_normalized == ptext_normalized:
                    result_url = purl
                    break
                
                fuzzy_score = fuzz.token_sort_ratio(name_lower, ptext_lower)
                partial_score = fuzz.partial_ratio(name_lower, ptext_lower)
                token_set_score = fuzz.token_set_ratio(name_lower, ptext_lower)
                
                max_fuzzy_score = max(fuzzy_score, partial_score, token_set_score)
                
                if max_fuzzy_score > best_match_score and max_fuzzy_score >= 70:
                    result_url = purl
                    best_match_score = max_fuzzy_score
                
                if len(name_normalized) > 5:
                    name_words = set(name_lower.split())
                    ptext_words = set(ptext_lower.split())
                    common_words = name_words & ptext_words
                    
                    if len(name_words) > 0:
                        word_match_ratio = len(common_words) / len(name_words) * 100
                        if word_match_ratio > best_match_score and word_match_ratio >= 70:
                            result_url = purl
                            best_match_score = word_match_ratio
            
            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            brand_cache[brand_key] = perfume_links
            
            if result_url:
                return result_url
        
        except Exception as e:
            pass
    
    # –ö–µ—à–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    brand_cache[brand_key] = []
    return None

def match_fragrantica_urls():
    print("\n" + "="*80)
    print("–®–ê–ì 3: –ü–û–ò–°–ö –ù–ê FRAGRANTICA")
    print("="*80 + "\n")
    
    print(f"üåê –ü—Ä–æ–∫—Å–∏: {SMARTPROXY_HOST}:{SMARTPROXY_PORT}")
    print(f"üë§ User: {SMARTPROXY_USER}\n")
    
    conn = sqlite3.connect('fragrantica_news.db')
    cursor = conn.cursor()
    
    try:
        cursor.execute('ALTER TABLE randewoo_products ADD COLUMN fragrantica_url TEXT')
        conn.commit()
    except:
        pass
    
    cursor.execute('SELECT id, brand, name FROM randewoo_products WHERE fragrantica_url IS NULL')
    products = cursor.fetchall()
    
    if not products:
        print("‚úì –í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –∏–º–µ—é—Ç Fragrantica URL")
        conn.close()
        return
    
    print(f"–¢–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(products)}\n")
    
    BATCH_SIZE = 10
    BATCH_PAUSE = 5  # –£–≤–µ–ª–∏—á–µ–Ω–∞ –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
    
    found = 0
    not_found = 0
    
    total_batches = (len(products) + BATCH_SIZE - 1) // BATCH_SIZE
    
    for batch_num in range(0, len(products), BATCH_SIZE):
        batch_products = products[batch_num:batch_num + BATCH_SIZE]
        current_batch = batch_num // BATCH_SIZE + 1
        
        print(f"{'='*80}")
        print(f"–ü–ê–ö–ï–¢ {current_batch}/{total_batches}")
        print(f"{'='*80}\n")
        
        scraper = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False}
        )
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–æ–∫—Å–∏ Smartproxy
        scraper.proxies = {
            'http': PROXY_URL,
            'https': PROXY_URL
        }
        brand_cache = {}
        
        for idx_in_batch, (product_id, brand, name) in enumerate(batch_products, 1):
            global_idx = batch_num + idx_in_batch
            
            print(f"[{global_idx}/{len(products)}] {brand} - {name}")
            print(f"  üîç –ò—â—É –Ω–∞ Fragrantica...", end=" ", flush=True)
            
            try:
                fragrantica_url = search_fragrantica(scraper, brand, name, brand_cache)
                
                if fragrantica_url:
                    cursor.execute('UPDATE randewoo_products SET fragrantica_url = ? WHERE id = ?', 
                                 (fragrantica_url, product_id))
                    conn.commit()
                    found += 1
                    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ")
                    print(f"     {fragrantica_url}")
                else:
                    not_found += 1
                    print(f"‚úó –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
                
                time.sleep(2)  # –£–≤–µ–ª–∏—á–µ–Ω–∞ –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
            except Exception as e:
                not_found += 1
                print(f"‚úó –û—à–∏–±–∫–∞: {e}")
        
        if current_batch < total_batches:
            print(f"\n‚è∏  –ü–∞—É–∑–∞ {BATCH_PAUSE} —Å–µ–∫...\n")
            time.sleep(BATCH_PAUSE)
    
    conn.close()
    
    print(f"\n{'='*80}")
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:")
    print(f"  –ù–∞–π–¥–µ–Ω–æ: {found} ({found/len(products)*100:.1f}%)")
    print(f"  –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {not_found}")
    print(f"{'='*80}")

# ============================================================================
# –®–ê–ì 4: –ü–ê–†–°–ò–ù–ì –ù–û–í–û–°–¢–ï–ô
# ============================================================================

def parse_perfume_news_article(scraper, product_id, fragrantica_url, max_retries=3):
    """
    –ü–∞—Ä—Å–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∞—Ä–æ–º–∞—Ç–∞ —Å retry –ª–æ–≥–∏–∫–æ–π
    
    Args:
        scraper: cloudscraper instance
        product_id: ID —Ç–æ–≤–∞—Ä–∞ –≤ –ë–î
        fragrantica_url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∞—Ä–æ–º–∞—Ç–∞
        max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    
    for attempt in range(max_retries):
        try:
            # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º (—É–≤–µ–ª–∏—á–µ–Ω–∞ —Å 2 –¥–æ 5 —Å–µ–∫)
            time.sleep(5)
            
            response = scraper.get(fragrantica_url, timeout=30)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            news_list = []
            news_blocks = soup.find_all('div', class_='newslist')
            
            for block in news_blocks:
                date_div = block.find('div', class_='right-bottom-corner-abs')
                if date_div:
                    date_str = date_div.get_text(strip=True)
                    try:
                        if len(date_str.split('/')[2].split(' ')[0]) == 2:
                            news_date = datetime.strptime(date_str, '%m/%d/%y %H:%M')
                        else:
                            news_date = datetime.strptime(date_str, '%m/%d/%Y %H:%M')
                        
                        # –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ >= 2024 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞)
                        if news_date.year == 2025:
                            title_tag = block.find('h4')
                            link_tag = block.find('a', href=True)
                            author_tag = block.find('p')
                            
                            if title_tag and link_tag:
                                news_title = title_tag.get_text(strip=True)
                                news_url = urljoin('https://www.fragrantica.ru', link_tag['href'])
                                author = author_tag.get_text(strip=True).replace('–æ—Ç', '').strip() if author_tag else None
                                
                                news_list.append({
                                    'product_id': product_id,
                                    'news_title': news_title,
                                    'news_url': news_url,
                                    'news_date': news_date,
                                    'author': author
                                })
                    except ValueError as e:
                        # –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É –Ω–æ–≤–æ—Å—Ç—å
                        continue
            
            return news_list
            
        except (ConnectionError, ConnectionResetError) as e:
            # –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - retry —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
            if attempt < max_retries - 1:
                wait_time = 10 * (2 ** attempt)  # 10, 20, 40 —Å–µ–∫—É–Ω–¥
                print(f"     ‚ö† –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}), –∂–¥—É {wait_time} —Å–µ–∫...")
                time.sleep(wait_time)
            else:
                print(f"     ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                return []
                
        except Exception as e:
            # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞
            print(f"     ‚úó –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {type(e).__name__}: {str(e)[:100]}")
            return []
    
    return []

def parse_all_news():
    print("\n" + "="*80)
    print("–®–ê–ì 4: –ü–ê–†–°–ò–ù–ì –ù–û–í–û–°–¢–ï–ô")
    print("="*80 + "\n")
    
    conn = sqlite3.connect('fragrantica_news.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT id, brand, name, fragrantica_url 
        FROM randewoo_products 
        WHERE fragrantica_url IS NOT NULL
    ''')
    products = cursor.fetchall()
    
    if not products:
        print("‚úó –ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ —Å Fragrantica URL")
        conn.close()
        return
    
    print(f"–¢–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(products)}\n")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞—Ç—á–µ–π
    BATCH_SIZE = 50  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ 50 —Ç–æ–≤–∞—Ä–æ–≤
    BATCH_PAUSE = 60  # –ü–∞—É–∑–∞ 60 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
    
    total_news = 0
    products_with_news = 0
    total_batches = (len(products) + BATCH_SIZE - 1) // BATCH_SIZE
    
    for batch_num in range(0, len(products), BATCH_SIZE):
        batch_products = products[batch_num:batch_num + BATCH_SIZE]
        current_batch = batch_num // BATCH_SIZE + 1
        
        print(f"\n{'='*80}")
        print(f"–ë–ê–¢–ß {current_batch}/{total_batches} (—Ç–æ–≤–∞—Ä—ã {batch_num + 1}-{min(batch_num + BATCH_SIZE, len(products))})")
        print(f"{'='*80}\n")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π scraper –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
        scraper = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False}
        )
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–æ–∫—Å–∏ Smartproxy
        scraper.proxies = {
            'http': PROXY_URL,
            'https': PROXY_URL
        }
        
        for idx_in_batch, (product_id, brand, name, fragrantica_url) in enumerate(batch_products, 1):
            global_idx = batch_num + idx_in_batch
            
            print(f"[{global_idx}/{len(products)}] {brand} - {name}", flush=True)
            print(f"  üîó URL: {fragrantica_url}", flush=True)
            print(f"  üì∞ –ü–∞—Ä—Å—é –Ω–æ–≤–æ—Å—Ç–∏...", end=" ", flush=True)
            
            try:
                news_list = parse_perfume_news_article(scraper, product_id, fragrantica_url)
                
                if news_list:
                    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ: {len(news_list)}", flush=True)
                    
                    for news in news_list:
                        try:
                            cursor.execute('''
                                INSERT OR IGNORE INTO perfume_news 
                                (product_id, news_title, news_url, news_date, author)
                                VALUES (?, ?, ?, ?, ?)
                            ''', (news['product_id'], news['news_title'], news['news_url'], 
                                  news['news_date'], news['author']))
                            print(f"     ‚Ä¢ {news['news_title'][:60]}... ({news['news_date'].strftime('%Y-%m-%d')})", flush=True)
                        except Exception as e:
                            print(f"     ‚ö† –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}", flush=True)
                    
                    conn.commit()
                    total_news += len(news_list)
                    products_with_news += 1
                else:
                    print(f"‚äò –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç", flush=True)
                
            except Exception as e:
                print(f"‚úó –û—à–∏–±–∫–∞: {e}", flush=True)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
        if current_batch < total_batches:
            print(f"\n‚è∏  –ü–ê–£–ó–ê {BATCH_PAUSE} –°–ï–ö –ü–ï–†–ï–î –°–õ–ï–î–£–Æ–©–ò–ú –ë–ê–¢–ß–ï–ú...\n", flush=True)
            time.sleep(BATCH_PAUSE)
    
    conn.close()
    
    print(f"\n{'='*80}")
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"  –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total_news}")
    print(f"  –ê—Ä–æ–º–∞—Ç–æ–≤ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏: {products_with_news}/{len(products)}")
    print(f"{'='*80}")

# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    print("\n" + "="*80, flush=True)
    print("–ì–õ–û–ë–ê–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì - –£–ú–ù–´–ô –†–ï–ñ–ò–ú", flush=True)
    print("="*80, flush=True)
    
    start_time = time.time()
    
    try:
        # ============================================================
        # –®–ê–ì 0: –ê–ù–ê–õ–ò–ó –°–û–°–¢–û–Ø–ù–ò–Ø –ë–î
        # ============================================================
        print("\n" + "="*80, flush=True)
        print("–®–ê–ì 0: –ê–ù–ê–õ–ò–ó –ë–î", flush=True)
        print("="*80 + "\n", flush=True)
        
        conn = sqlite3.connect('fragrantica_news.db', timeout=30)
        cursor = conn.cursor()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
        cursor.execute('SELECT COUNT(*) FROM randewoo_products')
        total_products = cursor.fetchone()[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ —Å Fragrantica URL
        cursor.execute('SELECT COUNT(*) FROM randewoo_products WHERE fragrantica_url IS NOT NULL')
        products_with_fragrantica = cursor.fetchone()[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
        cursor.execute('SELECT COUNT(*) FROM perfume_news')
        total_news = cursor.fetchone()[0]
        
        conn.close()
        
        print(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î:")
        print(f"  ‚Ä¢ –¢–æ–≤–∞—Ä–æ–≤ –≤ –ë–î: {total_products}")
        print(f"  ‚Ä¢ –° Fragrantica URL: {products_with_fragrantica}")
        print(f"  ‚Ä¢ –ù–æ–≤–æ—Å—Ç–µ–π –≤ –ë–î: {total_news}\n")
        
        # ============================================================
        # –ü–†–ò–ù–ò–ú–ê–ï–ú –†–ï–®–ï–ù–ò–ï –û –ü–õ–ê–ù–ï –î–ï–ô–°–¢–í–ò–ô
        # ============================================================
        
        if total_products == 0:
            print("üìã –ü–õ–ê–ù: –ü–û–õ–ù–´–ô –¶–ò–ö–õ (–ë–î –ø—É—Å—Ç–∞—è)")
            print("  1. ‚úì –ü–∞—Ä—Å–∏–Ω–≥ Randewoo")
            print("  2. ‚úì –ü–æ–∏—Å–∫ –Ω–∞ Fragrantica")
            print("  3. ‚úì –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π\n")
            
            products_count = parse_randewoo_with_selenium(MAX_PRODUCTS)
            
            if products_count == 0:
                print("\n‚úó –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            match_fragrantica_urls()
            parse_all_news()
            
        elif products_with_fragrantica == 0:
            print("üìã –ü–õ–ê–ù: –ü–û–ò–°–ö FRAGRANTICA + –ù–û–í–û–°–¢–ò")
            print("  1. ‚äò –ü–∞—Ä—Å–∏–Ω–≥ Randewoo (–ø—Ä–æ–ø—É—â–µ–Ω - —Ç–æ–≤–∞—Ä—ã –µ—Å—Ç—å)")
            print("  2. ‚úì –ü–æ–∏—Å–∫ –Ω–∞ Fragrantica")
            print("  3. ‚úì –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π\n")
            
            match_fragrantica_urls()
            parse_all_news()
            
        elif products_with_fragrantica < total_products:
            print("üìã –ü–õ–ê–ù: –î–û–ì–†–£–ó–ö–ê FRAGRANTICA + –ù–û–í–û–°–¢–ò")
            print("  1. ‚äò –ü–∞—Ä—Å–∏–Ω–≥ Randewoo (–ø—Ä–æ–ø—É—â–µ–Ω)")
            print("  2. ‚úì –ü–æ–∏—Å–∫ –Ω–∞ Fragrantica (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö)")
            print("  3. ‚úì –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π\n")
            
            match_fragrantica_urls()
            parse_all_news()
            
        else:
            print("üìã –ü–õ–ê–ù: –¢–û–õ–¨–ö–û –ù–û–í–û–°–¢–ò")
            print("  1. ‚äò –ü–∞—Ä—Å–∏–Ω–≥ Randewoo (–ø—Ä–æ–ø—É—â–µ–Ω)")
            print("  2. ‚äò –ü–æ–∏—Å–∫ –Ω–∞ Fragrantica (–ø—Ä–æ–ø—É—â–µ–Ω - –≤—Å–µ –Ω–∞–π–¥–µ–Ω—ã)")
            print("  3. ‚úì –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π\n")
            
            parse_all_news()
        
        elapsed = time.time() - start_time
        
        print("\n" + "="*80)
        print("–¶–ò–ö–õ –ó–ê–í–ï–†–®–ï–ù!")
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed/60:.1f} –º–∏–Ω—É—Ç")
        print("="*80 + "\n")
        
    except KeyboardInterrupt:
        print("\n\n‚ö† –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚úó –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()

